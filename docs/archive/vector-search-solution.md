# Vector Search 問題解決策

## 問題の特定

テスト関数の実行結果から、Vector Searchインデックスへのデータアップロードが失敗していた根本原因が特定できました。エラーメッセージは以下の通りです：

```json
{
  "error": {
    "code": 400,
    "message": "StreamUpdate is not enabled on this index Optional[7360896096425476096].",
    "status": "FAILED_PRECONDITION"
  }
}
```

## 問題の分析

このエラーは、現在のインデックスが「バッチ更新」モードで作成されており、`upsertDatapoints` APIを使用したリアルタイム更新（StreamUpdate）に対応していないことを示しています。

Vector Searchのインデックスには、主に2つの更新方法があります：

1. **バッチ更新（Batch Update）**:
   - インデックス全体を一度に更新する方式
   - Cloud Storage上のファイルを使用してインデックスを更新
   - コスト効率が良く、大量データの更新に適している
   - 更新が完了するまでに時間がかかる（数分〜数時間）

2. **ストリーミング更新（Stream Update）**:
   - リアルタイムにデータポイントを追加・更新する方式
   - `upsertDatapoints` APIを使用
   - 即時反映が必要な場合に適している
   - コストが高くなる場合がある

## 要件の再確認

プロジェクトの要件として「1日1回のアップデートで十分」とのことですので、リアルタイム更新機能（StreamUpdate）は必要ありません。むしろ、現在のバッチ更新方式のインデックスの方が要件に適しており、コスト効率も良いです。

## 解決策

現在のインデックスをそのまま利用し、Cloud Functionsの処理内容を変更して、バッチ更新方式を実装します。具体的な実装方法は「docs/vector-search-batch-update.md」に詳細に記載しています。

### 実装の概要

1. **データの準備**:
   - Confluenceから取得したデータをJSON形式のファイルとして作成

2. **Cloud Storageへのアップロード**:
   - 作成したJSONファイルをGCSにアップロード

3. **インデックスの更新**:
   - GCS上のファイルを使用してインデックスを更新

## メリット

1. **要件に最適**: 1日1回の更新という要件に最適なアーキテクチャ
2. **効率的**: 大規模なデータ更新を効率的に行える
3. **コスト効率**: ストリーミング更新に比べてコストが安価な場合が多い
4. **既存インデックスの活用**: 新しいインデックスを作成する必要がない

## 次のステップ

1. **GCSバケットの作成**: データアップロード用のGCSバケットを作成
2. **必要なパッケージのインストール**: `@google-cloud/storage` と `@google-cloud/aiplatform` をインストール
3. **Cloud Functions修正**: バッチ更新方式を実装するようにコードを修正
4. **テスト実行**: 修正したコードをデプロイしてテスト
