# RAGシステム ファイル取得・要約表示 仕様比較レポート

**作成日**: 2025年1月  
**目的**: 一般的なRAGシステムの仕様と現在の実装を比較し、差異と改善点を明確化

---

## 📊 比較サマリー

| カテゴリ | 一般的なRAG仕様 | 現在の実装 | 差異レベル | 優先度 |
|---------|----------------|-----------|-----------|--------|
| **ファイル取得** | 多様な形式、構造解析、メタデータ | ✅ 基本対応 | 中 | 中 |
| **チャンク分割** | セマンティック/階層的 | ⚠️ 固定サイズ | 大 | 高 |
| **メタデータ** | 見出し、ページ番号、セクション | ⚠️ 基本メタデータのみ | 中 | 中 |
| **要約表示** | 抽出型+生成型、粒度調整 | ✅ 生成型、ストリーミング | 小 | 低 |
| **参照元表示** | ページ番号、セクション | ✅ URL、タイトル | 小 | 低 |

---

## 1. ファイル取得の仕様比較

### 1.1 一般的なRAGシステムの仕様

#### 対応ファイル形式
- **標準形式**: PDF、Word (.doc, .docx)、PowerPoint (.ppt, .pptx)、Excel (.xls, .xlsx)
- **テキスト形式**: テキストファイル (.txt)、HTML、Markdown
- **画像形式**: PNG、JPG、JPEG（OCR対応）
- **構造化データ**: JSON、CSV、XML

#### ファイル構造の解析
- **見出し階層**: H1-H6の階層構造を保持
- **段落構造**: 段落単位での意味的区切りを認識
- **表構造**: テーブルの行・列構造を保持
- **画像・図表**: キャプションと関連テキストを関連付け
- **メタデータ**: 作成日、著者、ページ番号、セクション情報

#### 認証方式
- **OAuth2**: ユーザー認証によるアクセス
- **サービスアカウント**: 自動化されたバッチ処理
- **APIキー**: 公開データへのアクセス

### 1.2 現在の実装

#### 対応ファイル形式
- ✅ **Google Workspace**: Google Docs、Spreadsheet、Slides
- ✅ **標準形式**: PDF、テキストファイル、Markdown
- ❌ **Microsoft Office**: Word、PowerPoint、Excel（未対応）
- ❌ **画像**: OCR未対応

#### ファイル構造の解析
- ✅ **Google Spreadsheet**: シート名、テーブル構造を保持
- ✅ **Google Slides**: スライド単位、メモ取得
- ⚠️ **PDF**: テキスト抽出のみ（構造解析なし）
- ⚠️ **HTML**: ConfluenceのHTMLからテキスト抽出（構造の一部保持）

#### 認証方式
- ✅ **OAuth2**: Google Drive対応
- ✅ **サービスアカウント**: Google Drive、共有ドライブ対応
- ✅ **API Token**: Confluence、Jira対応

### 1.3 差異と改善点

#### ⚠️ 改善が必要な項目

**1. Microsoft Office形式の対応**
- **現状**: Word、PowerPoint、Excel未対応
- **影響**: 多くの企業文書がOffice形式のため、対応範囲が限定的
- **推奨対応**:
  - `mammoth`（Word）、`pptx`（PowerPoint）、`xlsx`（Excel）ライブラリの導入
  - または、Google Drive経由でOffice形式をGoogle Workspace形式に変換

**2. 画像のOCR対応**
- **現状**: 画像ファイル未対応
- **影響**: スキャン文書や画像内テキストが検索対象外
- **推奨対応**:
  - Google Cloud Vision APIまたはTesseract OCRの導入
  - PDF内画像のOCR処理

**3. 構造解析の強化**
- **現状**: 基本的なテキスト抽出のみ
- **影響**: 見出し階層やセクション情報が失われる
- **推奨対応**:
  - Markdown形式での構造保持（見出し、リスト、テーブル）
  - セクション単位でのメタデータ付与

---

## 2. チャンク分割の仕様比較

### 2.1 一般的なRAGシステムの仕様

#### チャンキング戦略

**1. セマンティックチャンキング（推奨）**
- **方法**: 意味的な単位（文、段落）で分割
- **特徴**:
  - 文の境界を考慮
  - 重要な情報が分割されにくい
  - 意味的なまとまりを保持

**2. 階層的チャンキング（高度）**
- **方法**: 見出し、段落、セクションなどの階層構造を考慮
- **特徴**:
  - ドキュメントの構造を保持
  - 関連する情報がまとまる
  - セクション単位での検索が可能

**3. 固定サイズチャンキング（基本）**
- **方法**: 固定サイズ（512文字、1024文字）で分割
- **特徴**:
  - 実装が簡単
  - パフォーマンスが良い
  - 文の境界を考慮しない（デメリット）

#### チャンクサイズの最適化
- **一般的なサイズ**: 512-2048トークン（約400-1600文字）
- **オーバーラップ**: 10-20%（約50-200文字）
- **意味的区切り**: 文の境界、段落の境界を考慮

### 2.2 現在の実装

#### チャンキング戦略

**実装**: 固定サイズチャンキング
- **Confluence**: 1800文字、200文字オーバーラップ
- **Jira**: 3000文字以上の場合のみチャンク分割（1800文字、200文字オーバーラップ）
- **Google Drive**: 1000文字、200文字オーバーラップ（⚠️ 仕様と差異）

**実装コード**:
```typescript
// src/lib/text-chunking.ts
export function chunkText(text: string, options: ChunkOptions = {}): TextChunk[] {
  const maxChunkSize = options.maxChunkSize || 1800;
  const overlap = options.overlap || 200;
  
  // 固定サイズで分割（意味的区切りなし）
  while (start < text.length) {
    const end = Math.min(start + maxChunkSize, text.length);
    const chunkText = text.substring(start, end).trim();
    // ...
  }
}
```

#### 課題
- ❌ **意味的区切りなし**: 文の途中で分割される可能性
- ❌ **構造情報の欠落**: 見出しやセクション情報が失われる
- ⚠️ **サイズの不統一**: Google Driveが1000文字（仕様1800文字）

### 2.3 差異と改善点

#### 🔴 高優先度: セマンティックチャンキングの導入

**現状の問題**:
- 文の途中で分割される可能性
- 重要な情報が複数のチャンクに分散
- 検索精度への影響

**推奨改善**:
```typescript
// セマンティックチャンキングの実装例
function semanticChunkText(text: string, maxChunkSize: number, overlap: number): TextChunk[] {
  // 1. 文の境界で分割（。！？）
  const sentences = text.split(/([。！？\n\n])/);
  
  // 2. 意味的なまとまりを考慮してチャンク化
  const chunks: TextChunk[] = [];
  let currentChunk = '';
  
  for (const sentence of sentences) {
    if ((currentChunk + sentence).length > maxChunkSize) {
      // チャンクを確定
      chunks.push({
        text: currentChunk.trim(),
        index: chunks.length,
        // ...
      });
      // オーバーラップ分を保持
      currentChunk = currentChunk.slice(-overlap) + sentence;
    } else {
      currentChunk += sentence;
    }
  }
  
  return chunks;
}
```

**段階的導入**:
1. **Phase 1**: 文の境界を考慮した分割（句点、改行）
2. **Phase 2**: 段落単位での分割
3. **Phase 3**: 見出し階層を考慮した階層的チャンキング

#### 🟡 中優先度: チャンクサイズの統一

**現状**: Google Driveが1000文字（仕様1800文字）
**推奨**: 全データソースで1800文字に統一

#### 🟡 中優先度: 階層的チャンキングの検討

**メリット**:
- セクション単位での検索が可能
- ドキュメント構造の保持
- より精度の高い検索結果

**実装例**:
```typescript
// 見出しを基準にした階層的チャンキング
function hierarchicalChunkText(markdown: string): TextChunk[] {
  // 見出し（##, ###）でセクション分割
  const sections = markdown.split(/^(#{1,6}\s.+)$/m);
  
  const chunks: TextChunk[] = [];
  for (const section of sections) {
    // セクション内をさらにチャンク化
    const sectionChunks = semanticChunkText(section, 1800, 200);
    chunks.push(...sectionChunks);
  }
  
  return chunks;
}
```

---

## 3. メタデータの仕様比較

### 3.1 一般的なRAGシステムの仕様

#### メタデータの種類
- **文書メタデータ**: タイトル、作成日、著者、更新日
- **構造メタデータ**: 見出し、ページ番号、セクション情報
- **コンテキストメタデータ**: 前後のチャンク情報、親セクション情報
- **検索メタデータ**: スコア、検索方法（ベクトル/BM25）、関連度

#### メタデータの活用
- **トレーサビリティ**: 情報の出所を明確化
- **検索精度向上**: メタデータを検索条件に使用
- **要約の品質向上**: セクション情報を要約に反映

### 3.2 現在の実装

#### 実装済みメタデータ
- ✅ **基本メタデータ**: タイトル、URL、更新日時、データソース
- ✅ **チャンクメタデータ**: chunkIndex、totalChunks
- ✅ **検索メタデータ**: スコア、検索方法
- ⚠️ **構造メタデータ**: 見出し、セクション情報は部分的

#### 不足しているメタデータ
- ❌ **ページ番号**: PDFや長文書での位置情報
- ❌ **セクション情報**: 見出し階層、セクション名
- ❌ **前後チャンク情報**: コンテキストの保持

### 3.3 差異と改善点

#### 🟡 中優先度: 構造メタデータの強化

**推奨改善**:
```typescript
interface EnhancedLanceDBRecord {
  // 既存フィールド
  id: string;
  title: string;
  content: string;
  
  // 追加メタデータ
  sectionTitle?: string;      // セクション見出し
  sectionLevel?: number;      // 見出しレベル（1-6）
  pageNumber?: number;        // ページ番号（PDF等）
  parentSection?: string;     // 親セクション名
  previousChunkId?: string;   // 前のチャンクID
  nextChunkId?: string;      // 次のチャンクID
}
```

**実装方法**:
1. Markdown解析時に見出し情報を抽出
2. チャンク分割時にセクション情報を付与
3. 前後チャンクのIDを記録

---

## 4. 要約表示の仕様比較

### 4.1 一般的なRAGシステムの仕様

#### 要約の種類

**1. 抽出型要約**
- **方法**: 原文から重要な部分を抜粋
- **特徴**: 正確性が高い、原文の表現を保持

**2. 生成型要約**
- **方法**: LLMが新たに文章を生成
- **特徴**: 読みやすい、情報を統合可能

**3. ハイブリッド要約**
- **方法**: 抽出型と生成型を組み合わせ
- **特徴**: 正確性と読みやすさの両立

#### 要約の粒度
- **全文要約**: ドキュメント全体の要約
- **セクション要約**: セクション単位の要約
- **ポイント要約**: 箇条書きでの要点整理

#### 要約のカスタマイズ
- **長さ調整**: 短い要約、詳細な要約
- **詳細度調整**: 概要のみ、詳細情報を含む
- **形式選択**: 箇条書き、段落形式、テーブル形式

### 4.2 現在の実装

#### 要約方式
- ✅ **生成型要約**: LLM（Gemini）による要約生成
- ✅ **ストリーミング**: リアルタイムでの回答生成
- ✅ **マークダウン形式**: 見出し、箇条書き、テーブル対応
- ⚠️ **抽出型要約**: 部分的（検索結果の抜粋表示）

#### 要約の特徴
- ✅ **参照元の明示**: タイトル、URL、Issue Key
- ✅ **構造化表示**: マークダウン形式での整理
- ✅ **コンテキスト保持**: 会話履歴を考慮
- ⚠️ **粒度調整**: ユーザー指定不可

### 4.3 差異と改善点

#### 🟢 低優先度: 要約方式の改善

**現状**: 生成型要約のみ
**推奨**: ハイブリッド要約の検討

**実装例**:
```typescript
// ハイブリッド要約の実装
async function hybridSummarize(
  question: string,
  documents: Document[]
): Promise<string> {
  // 1. 抽出型: 関連する重要な部分を抜粋
  const extractedParts = extractRelevantParts(documents, question);
  
  // 2. 生成型: 抜粋部分を基に要約生成
  const summary = await generateSummary(question, extractedParts);
  
  return summary;
}
```

#### 🟢 低優先度: 要約粒度の調整

**推奨機能**:
- ユーザーが要約の長さを選択（短い/標準/詳細）
- セクション単位での要約表示
- ポイント要約モード

---

## 5. 参照元表示の仕様比較

### 5.1 一般的なRAGシステムの仕様

#### 参照元の表示方法
- **ページ番号**: PDFや長文書での位置情報
- **セクション情報**: 見出し、セクション名
- **ハイパーリンク**: 元のドキュメントへのリンク
- **引用形式**: [1], [2]などの番号リンク

#### 参照元の精度
- **チャンク単位**: どのチャンクから情報を取得したか
- **セクション単位**: どのセクションから情報を取得したか
- **文単位**: どの文から情報を取得したか（高度）

### 5.2 現在の実装

#### 実装済み機能
- ✅ **URLリンク**: Confluence、Jira、Google Driveへのリンク
- ✅ **タイトル表示**: ドキュメントタイトル
- ✅ **Issue Key**: JiraのIssue Key表示
- ✅ **スコア表示**: 検索スコア（デバッグ用）

#### 不足している機能
- ❌ **ページ番号**: PDF等での位置情報
- ❌ **セクション情報**: 見出し、セクション名
- ⚠️ **チャンク情報**: chunkIndexは記録されているが表示されない

### 5.3 差異と改善点

#### 🟡 中優先度: セクション情報の表示

**推奨改善**:
```typescript
// 参照元表示の強化
interface EnhancedReference {
  title: string;
  url: string;
  sectionTitle?: string;  // セクション見出し
  sectionLevel?: number; // 見出しレベル
  chunkIndex?: number;   // チャンク番号
  pageNumber?: number;   // ページ番号（PDF等）
}
```

**表示例**:
```
参照元:
- [会員:アカウント情報 > ログイン認証] (Confluence)
- [CTJ-1234: 応募移管機能の開発 > 実装詳細] (Jira)
```

---

## 6. 総合的な改善推奨事項

### 6.1 優先度: 高

#### 1. セマンティックチャンキングの導入
- **影響**: 検索精度の向上、情報の欠落防止
- **工数**: 中（2-3週間）
- **効果**: 高

#### 2. チャンクサイズの統一
- **影響**: 一貫性の確保、仕様との整合
- **工数**: 低（1日）
- **効果**: 中

### 6.2 優先度: 中

#### 3. 構造メタデータの強化
- **影響**: 検索精度向上、参照元表示の改善
- **工数**: 中（1-2週間）
- **効果**: 中

#### 4. Microsoft Office形式の対応
- **影響**: 対応範囲の拡大
- **工数**: 中（1-2週間）
- **効果**: 中

#### 5. セクション情報の表示
- **影響**: 参照元の明確化
- **工数**: 低（3-5日）
- **効果**: 中

### 6.3 優先度: 低

#### 6. 画像のOCR対応
- **影響**: スキャン文書の検索対応
- **工数**: 高（3-4週間）
- **効果**: 低（用途が限定的）

#### 7. ハイブリッド要約の導入
- **影響**: 要約品質の向上
- **工数**: 中（1-2週間）
- **効果**: 低（現状の生成型要約で十分）

#### 8. 要約粒度の調整機能
- **影響**: ユーザビリティの向上
- **工数**: 低（3-5日）
- **効果**: 低（ニーズが限定的）

---

## 7. 実装ロードマップ

### Phase 1: チャンキング改善（2-3週間）
1. セマンティックチャンキングの実装
2. チャンクサイズの統一（Google Driveを1800文字に）
3. テストと検証

### Phase 2: メタデータ強化（1-2週間）
1. 構造メタデータの追加（見出し、セクション）
2. 前後チャンク情報の記録
3. 参照元表示の改善

### Phase 3: ファイル形式拡張（1-2週間）
1. Microsoft Office形式の対応
2. 構造解析の強化
3. テストと検証

### Phase 4: 高度な機能（オプション）
1. 画像OCR対応
2. ハイブリッド要約
3. 要約粒度調整

---

## 8. まとめ

### ✅ 現在の実装の強み
- **ストリーミング要約**: リアルタイムでの回答生成
- **マークダウン対応**: 構造化された表示
- **複数データソース**: Confluence、Jira、Google Drive統合
- **参照元の明示**: URL、タイトル、Issue Key

### ⚠️ 改善が必要な点
- **チャンキング戦略**: 固定サイズからセマンティックへ
- **メタデータ**: 構造情報の強化
- **ファイル形式**: Microsoft Office対応
- **チャンクサイズ**: Google Driveの統一

### 🎯 推奨アクション
1. **最優先**: セマンティックチャンキングの導入
2. **短期**: チャンクサイズの統一、構造メタデータの強化
3. **中期**: Microsoft Office形式の対応
4. **長期**: 画像OCR、高度な要約機能

---

## 9. 参考資料

- [RAG Best Practices - Microsoft Learn](https://learn.microsoft.com/ja-jp/azure/azure-arc/edge-rag/advanced-data-parsing)
- [RAG Chunking Strategies - Zenn](https://zenn.dev/microsoft/articles/rag_textbook)
- [Semantic Chunking - LangChain](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker)

