import { GoogleGenerativeAI } from '@google/generative-ai';
import { readFileSync, writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';
import { ConfluencePage } from './confluence-data-extractor';
import { deduplicateFunctionKeywords, deduplicateGlobalKeywords } from '../lib/keyword-deduplicator';

interface ExtractedKnowledge {
  pageId: string;
  pageTitle: string;
  extractedAt: string;
  functions: {
    [functionName: string]: string[];
  };
  confidence: number;
  metadata: {
    processingTime: number;
    tokenCount: number;
    model: string;
  };
}

interface LLMExtractionConfig {
  apiKey: string;
  model: string;
  batchSize: number;
  outputDir: string;
  maxRetries: number;
  delayBetweenRequests: number;
}

interface ProcessingStats {
  totalPages: number;
  processedPages: number;
  successfulExtractions: number;
  failedExtractions: number;
  averageConfidence: number;
  totalProcessingTime: number;
  startTime: string;
  endTime?: string;
}

export class LLMKnowledgeExtractor {
  private genAI: GoogleGenerativeAI;
  private model: any;
  private config: LLMExtractionConfig;

  constructor(config: LLMExtractionConfig) {
    this.config = config;
    this.genAI = new GoogleGenerativeAI(config.apiKey);
    this.model = this.genAI.getGenerativeModel({ model: config.model });
  }

  async extractFromPages(pages: ConfluencePage[]): Promise<ExtractedKnowledge[]> {
    console.log(`[LLMKnowledgeExtractor] Starting extraction from ${pages.length} pages`);
    
    const stats: ProcessingStats = {
      totalPages: pages.length,
      processedPages: 0,
      successfulExtractions: 0,
      failedExtractions: 0,
      averageConfidence: 0,
      totalProcessingTime: 0,
      startTime: new Date().toISOString()
    };

    const results: ExtractedKnowledge[] = [];
    const startTime = Date.now();

    // ãƒãƒƒãƒå‡¦ç†
    for (let i = 0; i < pages.length; i += this.config.batchSize) {
      const batch = pages.slice(i, i + this.config.batchSize);
      console.log(`[LLMKnowledgeExtractor] Processing batch ${Math.floor(i / this.config.batchSize) + 1}/${Math.ceil(pages.length / this.config.batchSize)}`);

      const batchResults = await this.processBatch(batch, stats);
      results.push(...batchResults);

      // ãƒãƒƒãƒé–“ã®é…å»¶
      if (i + this.config.batchSize < pages.length) {
        await this.delay(this.config.delayBetweenRequests);
      }
    }

    stats.endTime = new Date().toISOString();
    stats.totalProcessingTime = Date.now() - startTime;
    stats.averageConfidence = this.calculateAverageConfidence(results);

    // çµæœã®ä¿å­˜
    await this.saveResults(results, stats);

    console.log(`[LLMKnowledgeExtractor] Extraction completed. Success: ${stats.successfulExtractions}/${stats.totalPages}`);
    return results;
  }

  private async processBatch(pages: ConfluencePage[], stats: ProcessingStats): Promise<ExtractedKnowledge[]> {
    const batchResults = await Promise.allSettled(
      pages.map(page => this.extractFromPage(page))
    );

    const results: ExtractedKnowledge[] = [];
    
    batchResults.forEach((result, index) => {
      stats.processedPages++;
      
      if (result.status === 'fulfilled') {
        results.push(result.value);
        stats.successfulExtractions++;
      } else {
        console.error(`[LLMKnowledgeExtractor] Failed to process page ${pages[index].id}:`, result.reason);
        stats.failedExtractions++;
      }
    });

    return results;
  }

  private async extractFromPage(page: ConfluencePage): Promise<ExtractedKnowledge> {
    const startTime = Date.now();
    
    try {
      const prompt = this.buildPrompt(page);
      const response = await this.callLLMWithRetry(prompt);
      const extracted = this.parseResponse(response, page);
      
      const processingTime = Date.now() - startTime;
      
      return {
        ...extracted,
        metadata: {
          ...extracted.metadata,
          processingTime
        }
      };
    } catch (error) {
      console.error(`[LLMKnowledgeExtractor] Error processing page ${page.id}:`, error);
      throw error;
    }
  }

  private buildPrompt(page: ConfluencePage): string {
    const context = {
      pageTitle: page.title,
      parentTitle: page.parentTitle || 'ãªã—',
      labels: page.labels.join(', ') || 'ãªã—',
      url: page.url,
      lastModified: page.lastModified,
      author: page.author
    };

    return `# Role
ã‚ãªãŸã¯ä»•æ§˜æ›¸ã‚’åˆ†æã—ã€æ©Ÿèƒ½ã¨ãã‚Œã«ç´ã¥ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

# Context
ã“ã‚Œã‹ã‚‰æ¸¡ã™ãƒ†ã‚­ã‚¹ãƒˆã¯ã€å¤§è¦æ¨¡ãªã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æ›¸ã®ä¸€éƒ¨ã§ã™ã€‚
- ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: "${context.pageTitle}"
- è¦ªãƒšãƒ¼ã‚¸: "${context.parentTitle}"
- ãƒ©ãƒ™ãƒ«: "${context.labels}"
- URL: "${context.url}"
- æœ€çµ‚æ›´æ–°: "${context.lastModified}"
- ä½œæˆè€…: "${context.author}"

# Task
ä¸Šè¨˜ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ã¦ã€ã“ã®ãƒšãƒ¼ã‚¸ã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ä¸»è¦æ©Ÿèƒ½ã¨ã€é–¢é€£ã™ã‚‹æ“ä½œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

# Rules
- å‡ºåŠ›ã¯å¿…ãšJSONå½¢å¼ã«ã—ã¦ãã ã•ã„
- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: { "æ©Ÿèƒ½å": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...] }
- æ©Ÿèƒ½åã¯å…·ä½“çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã‚‚ã®ã«ã—ã¦ãã ã•ã„
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯æ¤œç´¢ã«æœ‰åŠ¹ãªã‚‚ã®ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„
- æ©Ÿèƒ½åã¯æœ€å¤§5å€‹ã¾ã§ã€å„æ©Ÿèƒ½ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯æœ€å¤§10å€‹ã¾ã§
- ä¿¡é ¼åº¦ã‚’0-1ã®æ•°å€¤ã§è©•ä¾¡ã—ã¦ãã ã•ã„

# Output Format
{
  "functions": {
    "æ©Ÿèƒ½å1": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"],
    "æ©Ÿèƒ½å2": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4"]
  },
  "confidence": 0.85
}

# Input
---
${page.content}
---`;
  }

  private async callLLMWithRetry(prompt: string): Promise<string> {
    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= this.config.maxRetries; attempt++) {
      try {
        const result = await this.model.generateContent(prompt);
        const response = await result.response;
        return response.text();
      } catch (error) {
        lastError = error as Error;
        
        if (attempt < this.config.maxRetries) {
          const delay = Math.pow(2, attempt) * 1000;
          console.log(`[LLMKnowledgeExtractor] LLM call failed (attempt ${attempt}), retrying in ${delay}ms...`);
          await this.delay(delay);
        }
      }
    }

    throw lastError || new Error('All LLM retry attempts failed');
  }

  private parseResponse(response: string, page: ConfluencePage): ExtractedKnowledge {
    try {
      // JSONéƒ¨åˆ†ã‚’æŠ½å‡º
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error('No JSON found in response');
      }

      const parsed = JSON.parse(jsonMatch[0]);
      
      if (!parsed.functions || typeof parsed.functions !== 'object') {
        throw new Error('Invalid response format: missing functions');
      }

      return {
        pageId: page.id,
        pageTitle: page.title,
        extractedAt: new Date().toISOString(),
        functions: parsed.functions,
        confidence: parsed.confidence || 0.5,
        metadata: {
          processingTime: 0, // å¾Œã§è¨­å®š
          tokenCount: response.length,
          model: this.config.model
        }
      };
    } catch (error) {
      console.error(`[LLMKnowledgeExtractor] Failed to parse response for page ${page.id}:`, error);
      console.error(`[LLMKnowledgeExtractor] Response:`, response);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºã®çµæœã‚’è¿”ã™
      return {
        pageId: page.id,
        pageTitle: page.title,
        extractedAt: new Date().toISOString(),
        functions: {},
        confidence: 0.0,
        metadata: {
          processingTime: 0,
          tokenCount: response.length,
          model: this.config.model
        }
      };
    }
  }

  private calculateAverageConfidence(results: ExtractedKnowledge[]): number {
    if (results.length === 0) return 0;
    
    const totalConfidence = results.reduce((sum, result) => sum + result.confidence, 0);
    return totalConfidence / results.length;
  }

  private async saveResults(results: ExtractedKnowledge[], stats: ProcessingStats): Promise<void> {
    mkdirSync(this.config.outputDir, { recursive: true });

    // ãƒ¡ã‚¤ãƒ³çµæœãƒ•ã‚¡ã‚¤ãƒ«
    const resultsFile = join(this.config.outputDir, 'extracted-knowledge.json');
    writeFileSync(resultsFile, JSON.stringify(results, null, 2));
    console.log(`[LLMKnowledgeExtractor] Results saved to: ${resultsFile}`);

    // çµ±è¨ˆæƒ…å ±
    const statsFile = join(this.config.outputDir, 'extraction-stats.json');
    writeFileSync(statsFile, JSON.stringify(stats, null, 2));
    console.log(`[LLMKnowledgeExtractor] Statistics saved to: ${statsFile}`);

    // çµ±åˆã•ã‚ŒãŸçŸ¥è­˜ãƒ™ãƒ¼ã‚¹
    const mergedKnowledge = this.mergeKnowledge(results);
    const knowledgeFile = join(this.config.outputDir, 'merged-knowledge.json');
    writeFileSync(knowledgeFile, JSON.stringify(mergedKnowledge, null, 2));
    console.log(`[LLMKnowledgeExtractor] Merged knowledge saved to: ${knowledgeFile}`);
  }

  private mergeKnowledge(results: ExtractedKnowledge[]): any {
    const merged: any = {
      functions: {},
      statistics: {
        totalFunctions: 0,
        totalKeywords: 0,
        totalPages: results.length,
        averageConfidence: this.calculateAverageConfidence(results)
      }
    };

    results.forEach(result => {
      Object.entries(result.functions).forEach(([functionName, keywords]) => {
        if (!merged.functions[functionName]) {
          merged.functions[functionName] = {
            keywords: [],
            sources: [],
            confidence: 0,
            lastUpdated: result.extractedAt
          };
        }

        // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®çµ±åˆ
        const existingKeywords = new Set(merged.functions[functionName].keywords);
        keywords.forEach(keyword => existingKeywords.add(keyword));
        merged.functions[functionName].keywords = Array.from(existingKeywords);

        // ã‚½ãƒ¼ã‚¹ã®è¿½åŠ 
        merged.functions[functionName].sources.push(result.pageId);

        // ä¿¡é ¼åº¦ã®æ›´æ–°ï¼ˆå¹³å‡ï¼‰
        const currentConfidence = merged.functions[functionName].confidence;
        const sourceCount = merged.functions[functionName].sources.length;
        merged.functions[functionName].confidence = 
          (currentConfidence * (sourceCount - 1) + result.confidence) / sourceCount;

        // æœ€çµ‚æ›´æ–°æ—¥æ™‚ã®æ›´æ–°
        if (new Date(result.extractedAt) > new Date(merged.functions[functionName].lastUpdated)) {
          merged.functions[functionName].lastUpdated = result.extractedAt;
        }
      });
    });

    // é‡è¤‡å‰Šé™¤ã®å®Ÿè¡Œ
    console.log('ğŸ”„ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡å‰Šé™¤ã‚’å®Ÿè¡Œä¸­...');
    const deduplicatedFunctions = deduplicateFunctionKeywords(merged.functions, {
      caseSensitive: false,
      trimWhitespace: true,
      normalizeSimilar: true,
      preserveOrder: true,
      minLength: 2,
      maxLength: 50
    });

    // ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡è¤‡å‰Šé™¤ã®å®Ÿè¡Œ
    const globalDeduplication = deduplicateGlobalKeywords(merged.functions, {
      caseSensitive: false,
      trimWhitespace: true,
      normalizeSimilar: true,
      preserveOrder: true,
      minLength: 2,
      maxLength: 50
    });

    // é‡è¤‡å‰Šé™¤çµæœã®é©ç”¨
    merged.functions = deduplicatedFunctions;
    
    // é‡è¤‡å‰Šé™¤çµ±è¨ˆã®è¿½åŠ 
    merged.statistics.deduplication = {
      globalReductionRate: globalDeduplication.statistics.reductionRate,
      totalDuplicatesRemoved: globalDeduplication.statistics.duplicateCount,
      totalSimilarRemoved: globalDeduplication.statistics.similarCount,
      originalKeywordCount: globalDeduplication.statistics.originalCount,
      finalKeywordCount: globalDeduplication.statistics.uniqueCount
    };

    // çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    merged.statistics.totalFunctions = Object.keys(merged.functions).length;
    merged.statistics.totalKeywords = Object.values(merged.functions)
      .reduce((sum: number, func: any) => sum + func.keywords.length, 0);

    console.log(`âœ… é‡è¤‡å‰Šé™¤å®Œäº†: ${globalDeduplication.statistics.reductionRate.toFixed(1)}%å‰Šæ¸›`);
    console.log(`   - å…ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: ${globalDeduplication.statistics.originalCount}`);
    console.log(`   - æœ€çµ‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: ${globalDeduplication.statistics.uniqueCount}`);
    console.log(`   - é‡è¤‡å‰Šé™¤: ${globalDeduplication.statistics.duplicateCount}å€‹`);
    console.log(`   - é¡ä¼¼å‰Šé™¤: ${globalDeduplication.statistics.similarCount}å€‹`);

    return merged;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
async function main() {
  const config: LLMExtractionConfig = {
    apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY || '',
    model: 'gemini-1.5-flash',
    batchSize: 5,
    outputDir: './data/llm-extraction',
    maxRetries: 3,
    delayBetweenRequests: 2000
  };

  if (!config.apiKey) {
    console.error('GEMINI_API_KEY or GOOGLE_API_KEY environment variable is required');
    process.exit(1);
  }

  // Confluenceãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
  const confluenceDataPath = './data/confluence-extraction/confluence-data.json';
  const confluenceData = JSON.parse(readFileSync(confluenceDataPath, 'utf-8'));

  const extractor = new LLMKnowledgeExtractor(config);
  
  try {
    const results = await extractor.extractFromPages(confluenceData.pages);
    console.log('LLM extraction completed successfully!');
    console.log(`Processed ${results.length} pages`);
  } catch (error) {
    console.error('LLM extraction failed:', error);
    process.exit(1);
  }
}

if (require.main === module) {
  main();
}

export { type ExtractedKnowledge, type LLMExtractionConfig, type ProcessingStats };
