/**
 * æ—¥æœ¬èªåˆ†ã‹ã¡æ›¸ããƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
 * kuromojiã‚’ä½¿ç”¨ã—ã¦æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†ã‹ã¡æ›¸ãã«å¤‰æ›
 */

import kuromoji from 'kuromoji';
import * as path from 'path';
import { saveTokenizerState, loadTokenizerState } from './persistent-cache';

/**
 * kuromojiã®è¾æ›¸ãƒ‘ã‚¹ã‚’ç’°å¢ƒã«å¿œã˜ã¦æ±ºå®š
 * - ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: node_modules/kuromoji/dict
 * - æœ¬ç•ªç’°å¢ƒï¼ˆCloud Runï¼‰: .next/standalone/node_modules/kuromoji/dict
 */
function getDictionaryPath(): string {
  // ç’°å¢ƒåˆ¤å®šã‚’å‹•çš„ã«è¡Œã†ï¼ˆå¾ªç’°ä¾å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ã€ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãªã„ï¼‰
  const isCloudRun = !!process.env.K_SERVICE;
  
  if (isCloudRun) {
    // Cloud Runç’°å¢ƒ: å®Ÿè¡Œæ™‚ã®process.cwd()ã¯/workspace/.next/standalone
    // ãã®ãŸã‚ã€ç›¸å¯¾ãƒ‘ã‚¹ã§.node_modules/kuromoji/dictã‚’æ¢ã™
    // ã¾ãŸã¯ã€/workspaceã‚’åŸºæº–ã«ã—ãŸçµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    const cwd = process.cwd();
    
    // ãƒ‘ã‚¿ãƒ¼ãƒ³1: ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒstandaloneå†…ã®å ´åˆ
    if (cwd.endsWith('.next/standalone') || cwd.includes('.next/standalone')) {
      // standaloneå†…ã®node_modulesã‚’æ¢ã™
      const standalonePath = path.resolve(cwd, 'node_modules/kuromoji/dict');
      return standalonePath;
    }
    
    // ãƒ‘ã‚¿ãƒ¼ãƒ³2: /workspaceã‚’åŸºæº–ã«ã—ãŸãƒ‘ã‚¹
    // process.cwd()ãŒ/workspace/.next/standaloneã®å ´åˆã€/workspaceã«æˆ»ã‚‹
    const workspaceRoot = cwd.replace(/\.next\/standalone.*$/, '');
    const standalonePath = path.resolve(workspaceRoot, '.next/standalone/node_modules/kuromoji/dict');
    return standalonePath;
  } else {
    // ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: é€šå¸¸ã®node_moduleså†…ã®è¾æ›¸ã‚’ä½¿ç”¨
    const localPath = path.resolve(process.cwd(), 'node_modules/kuromoji/dict');
    return localPath;
  }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã§Tokenizerã‚’ç®¡ç†
let tokenizer: kuromoji.Tokenizer<kuromoji.IpadicFeatures> | null = null;
let tokenizerPromise: Promise<kuromoji.Tokenizer<kuromoji.IpadicFeatures>> | null = null;
let dictionaryChecked: boolean = false; // è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã‚’ä¸€åº¦ã ã‘è¡Œã†
let verifiedDictionaryPath: string | null = null; // æ¤œè¨¼æ¸ˆã¿ã®è¾æ›¸ãƒ‘ã‚¹ã‚’ä¿æŒï¼ˆå†è¨ˆç®—ã‚’é˜²ãï¼‰

/**
 * kuromojiãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’äº‹å‰åˆæœŸåŒ–
 * âš¡ æœ€é©åŒ–: æ°¸ç¶šåŒ–ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§è¶…é«˜é€Ÿèµ·å‹•ã‚’å®Ÿç¾
 * â˜…â˜…â˜… ä¿®æ­£: ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ã«é–¢ã‚ã‚‰ãšã€å®Ÿéš›ã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ– â˜…â˜…â˜…
 * ç†ç”±: ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ã ã‘ã§ã¯ã€å®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä¿æŒã•ã‚Œãªã„
 */
export async function preInitializeTokenizer(): Promise<void> {
  // âš¡ æœ€å„ªå…ˆ: æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯å³åº§ã«è¿”ã™
  if (tokenizer) {
    console.log('[JapaneseTokenizer] ğŸš€ Tokenizer already initialized');
    return;
  }
  
  // âš¡ åˆæœŸåŒ–ä¸­ã®å ´åˆã¯ã€æ—¢å­˜ã®Promiseã‚’å¾…ã¤ï¼ˆé‡è¤‡åˆæœŸåŒ–ã‚’å®Œå…¨ã«é˜²æ­¢ï¼‰
  if (tokenizerPromise) {
    console.log('[JapaneseTokenizer] â³ Tokenizer initialization in progress, waiting...');
    await tokenizerPromise;
    return;
  }
  
  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰åˆæœŸåŒ–çŠ¶æ…‹ã‚’ç¢ºèªï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰
  const cachedState = loadTokenizerState();
  if (cachedState?.isInitialized) {
    console.log('[JapaneseTokenizer] ğŸš€ Fast startup: Using cached tokenizer state');
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ãŒã‚ã£ã¦ã‚‚ã€å®Ÿéš›ã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹
  }
  
  console.log('[JapaneseTokenizer] Initializing tokenizer...');
  const startTime = Date.now();
  await getTokenizer(); // å®Ÿéš›ã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–
  const initTime = Date.now() - startTime;
  
  // åˆæœŸåŒ–çŠ¶æ…‹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
  saveTokenizerState(true, Date.now());
  console.log(`[JapaneseTokenizer] âœ… Tokenizer initialized and cached in ${initTime}ms`);
}

/**
 * kuromojiãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’é…å»¶åˆæœŸåŒ–
 * âš¡ æœ€é©åŒ–: å®Ÿéš›ã«å¿…è¦ã«ãªã£ãŸæ™‚ã«åˆæœŸåŒ–
 */
export async function preInitializeTokenizerLazy(): Promise<void> {
  // âš¡ æœ€é©åŒ–: è»½é‡ãªåˆæœŸåŒ–ã®ã¿å®Ÿè¡Œ
  // é‡ã„è¾æ›¸èª­ã¿è¾¼ã¿ã¯å®Ÿéš›ã®ä½¿ç”¨æ™‚ã«å®Ÿè¡Œ
  console.log('[JapaneseTokenizer] âš¡ Lazy initialization started');
  
  // è»½é‡ãªåˆæœŸåŒ–å‡¦ç†ï¼ˆè¾æ›¸èª­ã¿è¾¼ã¿ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
  return new Promise<void>((resolve) => {
    setTimeout(() => {
      console.log('[JapaneseTokenizer] âš¡ Lazy initialization completed (dictionary loading deferred)');
      resolve();
    }, 100); // 100msã§å®Œäº†
  });
}

/**
 * ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–çŠ¶æ…‹ã‚’ç¢ºèª
 */
export function isTokenizerInitialized(): boolean {
  return tokenizer !== null;
}

/**
 * kuromojiãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
 * âš¡ æœ€é©åŒ–: æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯ä¸€åˆ‡ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ã‚°ãƒ¬ãƒ¼ãƒ‰é˜²æ­¢ï¼‰
 */
async function getTokenizer(): Promise<kuromoji.Tokenizer<kuromoji.IpadicFeatures>> {
  // âš¡ æœ€å„ªå…ˆ: æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯å³åº§ã«è¿”ã™ï¼ˆè¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ã‚‚å«ã‚ã¦ä¸€åˆ‡ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
  if (tokenizer) {
    return tokenizer;
  }

  // åˆæœŸåŒ–ä¸­ã®å ´åˆã¯ã€æ—¢å­˜ã®Promiseã‚’è¿”ã™
  if (tokenizerPromise) {
    return tokenizerPromise;
  }

  // âš¡ æœ€é©åŒ–: è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã‚’ä¸€åº¦ã ã‘è¡Œã†ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é˜²ãï¼‰
  // æ¤œè¨¼æ¸ˆã¿ã®ãƒ‘ã‚¹ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ç’°å¢ƒã«å¿œã˜ã¦æ±ºå®š
  let dicPath: string;
  
  if (verifiedDictionaryPath) {
    // æ—¢ã«æ¤œè¨¼æ¸ˆã¿ã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼ˆå†è¨ˆç®—ã‚’é˜²ãï¼‰
    dicPath = verifiedDictionaryPath;
  } else {
    // åˆå›ã®ã¿: ç’°å¢ƒã«å¿œã˜ã¦è¾æ›¸ãƒ‘ã‚¹ã‚’æ±ºå®š
    dicPath = getDictionaryPath();
    
    if (!dictionaryChecked) {
      const fs = await import('fs');
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ¬ç•ªç’°å¢ƒã§standaloneãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€é€šå¸¸ã®node_modulesã‚’è©¦ã™
      if (!fs.existsSync(dicPath)) {
        const fallbackPath = path.resolve(process.cwd(), 'node_modules/kuromoji/dict');
        if (fs.existsSync(fallbackPath)) {
          dicPath = fallbackPath;
          console.log(`[JapaneseTokenizer] âš ï¸  Primary path not found, using fallback: ${fallbackPath}`);
        } else {
          const errorMsg = `Kuromoji dictionary directory not found at ${dicPath} or ${fallbackPath}. Please ensure kuromoji is properly installed with 'npm install kuromoji'`;
          console.error(`[JapaneseTokenizer] âŒ ${errorMsg}`);
          throw new Error(errorMsg);
        }
      }

      // è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆä¸»è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
      const requiredFiles = ['base.dat.gz', 'check.dat.gz', 'cc.dat.gz'];
      const missingFiles = requiredFiles.filter(file => !fs.existsSync(path.join(dicPath, file)));
      if (missingFiles.length > 0) {
        const errorMsg = `Kuromoji dictionary files missing: ${missingFiles.join(', ')}. Please ensure kuromoji is properly installed with 'npm install kuromoji'`;
        console.error(`[JapaneseTokenizer] âŒ ${errorMsg}`);
        throw new Error(errorMsg);
      }
      
      // æ¤œè¨¼æ¸ˆã¿ãƒ‘ã‚¹ã‚’ä¿å­˜ï¼ˆæ¬¡å›ä»¥é™ã¯å†è¨ˆç®—ãƒ»å†ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
      verifiedDictionaryPath = dicPath;
      dictionaryChecked = true;
      console.log(`[JapaneseTokenizer] âœ… Dictionary files verified at: ${dicPath}`);
    }
  }

  tokenizerPromise = new Promise((resolve, reject) => {
    // âš¡ æœ€é©åŒ–: ãƒ­ã‚°ã‚’1å›ã ã‘å‡ºåŠ›ï¼ˆé‡è¤‡ãƒ­ã‚°ã‚’é˜²æ­¢ï¼‰
    // dictionaryCheckedãŒfalseã®å ´åˆã®ã¿ãƒ­ã‚°ã‚’å‡ºåŠ›ï¼ˆåˆå›ã®ã¿ï¼‰
    // æ³¨æ„: dictionaryCheckedã¯è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªãŒå®Œäº†ã—ãŸã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
    // tokenizerãŒnullã®å ´åˆã§ã‚‚ã€dictionaryCheckedãŒtrueã®å¯èƒ½æ€§ãŒã‚ã‚‹ï¼ˆå‰å›ã®åˆæœŸåŒ–è©¦è¡Œã§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ï¼‰
    if (!dictionaryChecked) {
      console.log(`[JapaneseTokenizer] ğŸ”§ Initializing kuromoji tokenizer with path: ${dicPath}...`);
      console.log(`[JapaneseTokenizer] ğŸ“¦ This is the FIRST initialization - dictionary files will be loaded once`);
    } else {
      // æ—¢ã«è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒã‚§ãƒƒã‚¯æ¸ˆã¿ã®å ´åˆï¼ˆå‰å›ã®åˆæœŸåŒ–è©¦è¡Œã§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ã ãŒã€tokenizerãŒnullã®å ´åˆï¼‰
      // ã“ã‚Œã¯æ­£å¸¸ãªã‚±ãƒ¼ã‚¹ï¼ˆã‚¨ãƒ©ãƒ¼ã§åˆæœŸåŒ–ãŒå¤±æ•—ã—ãŸå ´åˆãªã©ï¼‰
      console.log(`[JapaneseTokenizer] ğŸ”§ Initializing kuromoji tokenizer (dictionary already verified at: ${verifiedDictionaryPath || dicPath})...`);
    }
    kuromoji.builder({ dicPath: dicPath }).build((err, t) => {
      if (err) {
        console.error('[JapaneseTokenizer] âŒ Failed to initialize kuromoji:', err);
        tokenizerPromise = null; // ã‚¨ãƒ©ãƒ¼æ™‚ã¯Promiseã‚’ãƒªã‚»ãƒƒãƒˆ
        reject(err);
        return;
      }
      if (!dictionaryChecked) {
        console.log('[JapaneseTokenizer] âœ… Kuromoji tokenizer initialized successfully (FIRST TIME ONLY)');
        console.log('[JapaneseTokenizer] ğŸš€ Tokenizer is now cached in memory - no more dictionary loading');
      }
      tokenizer = t;
      tokenizerPromise = null; // åˆæœŸåŒ–å®Œäº†å¾Œã¯Promiseã‚’ãƒªã‚»ãƒƒãƒˆ
      resolve(t);
    });
  });

  return tokenizerPromise;
}

/**
 * æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†ã‹ã¡æ›¸ãã•ã‚ŒãŸæ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹
 * â˜…â˜…â˜… ä¿®æ­£: kuromojiã‚’ç¢ºå®Ÿã«ä½¿ç”¨ã™ã‚‹ï¼ˆè»½é‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã«ã‚ˆã‚‹å•é¡Œã‚’å›é¿ï¼‰ â˜…â˜…â˜…
 * ç†ç”±: è»½é‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãŒã€Œè‡ªå‹•ã‚ªãƒ•ã‚¡ãƒ¼ã€ã‚’ã€Œã€‘è‡ªå‹•ã‚ªãƒ•ã‚¡ãƒ¼è¨­å®šæ©Ÿèƒ½ã€ã®ã‚ˆã†ã«é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³ã«ã—ã€
 *       æ¤œç´¢ã‚¯ã‚¨ãƒªã€Œè‡ªå‹•ã‚ªãƒ•ã‚¡ãƒ¼ã€ã¨å®Œå…¨ä¸€è‡´ã—ãªã„å•é¡Œã‚’è§£æ±º
 * @param text å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã‚‰ã‚ŒãŸå˜èªã®æ–‡å­—åˆ— (ä¾‹: "æ•™å®¤ ç®¡ç† ã® ä»•æ§˜")
 */
export async function tokenizeJapaneseText(text: string): Promise<string> {
  if (!text || typeof text !== 'string') {
    return '';
  }

  try {
    // â˜…â˜…â˜… ä¿®æ­£: kuromojiãŒåˆæœŸåŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤ï¼ˆè»½é‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‚’ä½¿ã‚ãªã„ï¼‰ â˜…â˜…â˜…
    // ç†ç”±: è»½é‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãŒé•·ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ã€Lunrã®å®Œå…¨ä¸€è‡´æ¤œç´¢ã¨äº’æ›æ€§ãŒãªã„
    // å‚è€ƒ: docs/analysis/auto-offer-search-issue-root-cause.md
    const tokenizerInstance = await getTokenizer(); // åˆæœŸåŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤
    
    const tokens = tokenizerInstance.tokenize(text);
    
    // å…¨ã¦ã®å˜èªï¼ˆåè©ã€å‹•è©ã€åŠ©è©ãªã©ï¼‰ã‚’ãã®ã¾ã¾ã‚¹ãƒšãƒ¼ã‚¹ã§é€£çµ
    const tokenizedText = tokens.map(t => t.surface_form).join(' ');
    
    // âš¡ æœ€é©åŒ–: ãƒãƒƒãƒå‡¦ç†æ™‚ã¯ãƒ­ã‚°ã‚’æŠ‘åˆ¶ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
    // ãƒ‡ãƒãƒƒã‚°æ™‚ã®ã¿ãƒ­ã‚°ã‚’å‡ºåŠ›ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡å¯èƒ½ï¼‰
    if (process.env.DEBUG_TOKENIZATION === 'true') {
      console.log(`[JapaneseTokenizer] Tokenized: "${text}" -> "${tokenizedText}"`);
    }
    return tokenizedText;
  } catch (error) {
    console.error('[JapaneseTokenizer] Tokenization failed:', error);
    // â˜…â˜…â˜… ä¿®æ­£: ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è»½é‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‚’ä½¿ã‚ãšã€ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹ â˜…â˜…â˜…
    // ç†ç”±: è»½é‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ä¸ä¸€è‡´ã®å•é¡Œã‚’å›é¿
    throw new Error(`Failed to tokenize Japanese text: ${error instanceof Error ? error.message : String(error)}`);
  }
}

/**
 * è»½é‡ãªæ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆkuromojiãªã—ï¼‰
 * âš¡ æœ€é©åŒ–: ç°¡å˜ãªæ–‡å­—åˆ†å‰²ã§é«˜é€Ÿå‡¦ç†
 */
function performLightweightTokenization(text: string): string {
  // ç°¡å˜ãªæ–‡å­—åˆ†å‰²ï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã€è‹±æ•°å­—ã®å¢ƒç•Œã§åˆ†å‰²ï¼‰
  const tokens = text
    .replace(/([ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—]+)/g, '$1 ') // æ—¥æœ¬èªæ–‡å­—ã®å¾Œã«ã‚¹ãƒšãƒ¼ã‚¹
    .replace(/([a-zA-Z0-9]+)/g, '$1 ') // è‹±æ•°å­—ã®å¾Œã«ã‚¹ãƒšãƒ¼ã‚¹
    .trim()
    .split(/\s+/)
    .filter(token => token.length > 0);
  
  const result = tokens.join(' ');
  // âš¡ æœ€é©åŒ–: ãƒãƒƒãƒå‡¦ç†æ™‚ã¯ãƒ­ã‚°ã‚’æŠ‘åˆ¶ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
  if (process.env.DEBUG_TOKENIZATION === 'true') {
    console.log(`[JapaneseTokenizer] âš¡ Lightweight tokenized: "${text}" -> "${result}"`);
  }
  return result;
}

/**
 * è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ‹¬ã§åˆ†ã‹ã¡æ›¸ãã«å¤‰æ›ã™ã‚‹
 * @param texts å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆé…åˆ—
 * @returns åˆ†ã‹ã¡æ›¸ãã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆé…åˆ—
 */
export async function tokenizeJapaneseTexts(texts: string[]): Promise<string[]> {
  if (!Array.isArray(texts)) {
    return [];
  }

  try {
    const tokenizer = await getTokenizer();
    return texts.map(text => {
      if (!text || typeof text !== 'string') {
        return '';
      }
      
      const tokens = tokenizer.tokenize(text);
      return tokens.map(t => t.surface_form).join(' ');
    });
  } catch (error) {
    console.error('[JapaneseTokenizer] Batch tokenization failed:', error);
    // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
    return texts;
  }
}

/**
 * åè©ã®ã¿ã‚’æŠ½å‡ºã—ã¦åˆ†ã‹ã¡æ›¸ãã™ã‚‹ï¼ˆã‚ˆã‚Šç²¾å¯†ãªæ¤œç´¢ç”¨ï¼‰
 * @param text å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns åè©ã®ã¿ã®åˆ†ã‹ã¡æ›¸ãæ–‡å­—åˆ—
 */
export async function tokenizeJapaneseNouns(text: string): Promise<string> {
  if (!text || typeof text !== 'string') {
    return '';
  }

  try {
    const tokenizer = await getTokenizer();
    const tokens = tokenizer.tokenize(text);
    
    // åè©ã®ã¿ã‚’æŠ½å‡ºï¼ˆä¸€èˆ¬åè©ã€å›ºæœ‰åè©ã€ã‚µå¤‰åè©ãªã©ï¼‰
    const nouns = tokens
      .filter(t => {
        const pos = t.part_of_speech;
        return pos && Array.isArray(pos) && pos.some(p => p.includes('åè©')) && 
               !pos.some(p => p.includes('éè‡ªç«‹')) && !pos.some(p => p.includes('æ¥å°¾'));
      })
      .map(t => t.surface_form);
    
    const tokenizedText = nouns.join(' ');
    // âš¡ æœ€é©åŒ–: ãƒãƒƒãƒå‡¦ç†æ™‚ã¯ãƒ­ã‚°ã‚’æŠ‘åˆ¶ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
    if (process.env.DEBUG_TOKENIZATION === 'true') {
      console.log(`[JapaneseTokenizer] Nouns only: "${text}" -> "${tokenizedText}"`);
    }
    return tokenizedText;
  } catch (error) {
    console.error('[JapaneseTokenizer] Noun tokenization failed:', error);
    return text;
  }
}

/**
 * ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®çŠ¶æ…‹ã‚’å–å¾—
 */
export function getTokenizerStatus(): { initialized: boolean; error?: string } {
  return {
    initialized: tokenizer !== null,
    error: tokenizerPromise ? undefined : 'Not initialized'
  };
}

/**
 * ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
 */
export function resetTokenizer(): void {
  tokenizer = null;
  tokenizerPromise = null;
}
