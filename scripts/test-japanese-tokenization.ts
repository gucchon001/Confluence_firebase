/**
 * æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 * kuromojiã«ã‚ˆã‚‹åˆ†ã‹ã¡æ›¸ãã®å‹•ä½œã‚’ç¢ºèª
 */

import 'dotenv/config';
import { tokenizeJapaneseText, tokenizeJapaneseNouns, getTokenizerStatus } from '../src/lib/japanese-tokenizer';

async function testJapaneseTokenization() {
  console.log('ğŸ” æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹\n');
  
  // ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®çŠ¶æ…‹ç¢ºèª
  const status = getTokenizerStatus();
  console.log(`ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼çŠ¶æ…‹: ${status.initialized ? 'åˆæœŸåŒ–æ¸ˆã¿' : 'æœªåˆæœŸåŒ–'}`);
  if (status.error) {
    console.log(`âŒ ã‚¨ãƒ©ãƒ¼: ${status.error}`);
  }
  
  const testTexts = [
    'æ•™å®¤ç®¡ç†ã®ä»•æ§˜',
    'ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ã®è©³ç´°',
    'æ€¥å‹Ÿã®è¨­å®šæ–¹æ³•',
    'ä¼šå“¡ç™»éŒ²ã®æµã‚Œ',
    'æ±‚äººæƒ…å ±ã®ç·¨é›†',
    'ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶å®šç¾©æ›¸',
    'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ',
    'APIä»•æ§˜æ›¸',
    'ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹',
    'èªè¨¼ãƒ»èªå¯æ©Ÿèƒ½'
  ];
  
  console.log('\nğŸ“ åˆ†ã‹ã¡æ›¸ããƒ†ã‚¹ãƒˆ:');
  console.log('='.repeat(60));
  
  for (const text of testTexts) {
    try {
      const tokenized = await tokenizeJapaneseText(text);
      const nounsOnly = await tokenizeJapaneseNouns(text);
      
      console.log(`åŸæ–‡: "${text}"`);
      console.log(`åˆ†ã‹ã¡æ›¸ã: "${tokenized}"`);
      console.log(`åè©ã®ã¿: "${nounsOnly}"`);
      console.log('-'.repeat(40));
    } catch (error) {
      console.log(`âŒ ã‚¨ãƒ©ãƒ¼: "${text}" - ${error}`);
    }
  }
  
  // é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ
  console.log('\nğŸ“„ é•·æ–‡ãƒ†ã‚¹ãƒˆ:');
  const longText = 'ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å¡¾è¬›å¸«ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®é‹å–¶ã«å¿…è¦ãªæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚ä¼šå“¡ç™»éŒ²ã€æ±‚äººæƒ…å ±ã®ç®¡ç†ã€æ•™å®¤äºˆç´„ã€å¿œå‹Ÿç®¡ç†ãªã©ã®æ©Ÿèƒ½ã‚’åŒ…æ‹¬çš„ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚';
  
  try {
    const tokenized = await tokenizeJapaneseText(longText);
    const nounsOnly = await tokenizeJapaneseNouns(longText);
    
    console.log(`åŸæ–‡: "${longText}"`);
    console.log(`åˆ†ã‹ã¡æ›¸ã: "${tokenized}"`);
    console.log(`åè©ã®ã¿: "${nounsOnly}"`);
  } catch (error) {
    console.log(`âŒ é•·æ–‡ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: ${error}`);
  }
  
  // è‹±èªæ··ã˜ã‚Šãƒ†ã‚­ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ
  console.log('\nğŸŒ è‹±èªæ··ã˜ã‚Šãƒ†ã‚­ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ:');
  const mixedTexts = [
    'APIä»•æ§˜æ›¸ã®ä½œæˆ',
    'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆæ›¸',
    'ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆ',
    'èªè¨¼ãƒ»èªå¯æ©Ÿèƒ½ã®å®Ÿè£…',
    'Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™º'
  ];
  
  for (const text of mixedTexts) {
    try {
      const tokenized = await tokenizeJapaneseText(text);
      console.log(`"${text}" -> "${tokenized}"`);
    } catch (error) {
      console.log(`âŒ ã‚¨ãƒ©ãƒ¼: "${text}" - ${error}`);
    }
  }
  
  console.log('\nâœ… æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†');
}

// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
testJapaneseTokenization().catch(console.error);
