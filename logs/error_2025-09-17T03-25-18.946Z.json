{
  "operation": "embedding_batch_generation",
  "code": "batch_processing_error",
  "message": "Could not locate file: \"https://huggingface.co/sentence-transformers/LaBSE/resolve/main/onnx/model_quantized.onnx\".",
  "timestamp": "2025-09-17T03:25:18.946Z",
  "context": {
    "batchCount": 4
  },
  "stack": "Error: Could not locate file: \"https://huggingface.co/sentence-transformers/LaBSE/resolve/main/onnx/model_quantized.onnx\".\n    at handleError (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\utils\\hub.js:238:11)\n    at getModelFile (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\utils\\hub.js:471:24)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async constructSession (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\models.js:123:18)\n    at async Promise.all (index 1)\n    at async Function.from_pretrained (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\models.js:793:20)\n    at async Function.from_pretrained (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\models.js:5519:20)\n    at async Promise.all (index 1)\n    at async loadItems (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\pipelines.js:3279:5)\n    at async pipeline (C:\\dev\\CODE\\Confluence_firebase\\node_modules\\@xenova\\transformers\\src\\pipelines.js:3219:21)"
}